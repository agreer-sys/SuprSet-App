Voice Ducking Bus — Drop‑in (v1.0)

Purpose: Route coach voice (Realtime API / <audio> / MediaStream / browser TTS) through a WebAudio gain bus so beeps can duck voice by ~6 dB and we can suppress new TTS starts inside a small guard window around beeps.

⸻

1) /audio/voiceBus.ts — WebAudio voice bus with ducking

// /audio/voiceBus.ts
// Single, shared bus for coach voice. Works with <audio>, MediaStream, or browser TTS.

export type VoiceSource = 'mediaElement' | 'mediaStream' | 'none';

function dbToGain(db: number){
  return Math.pow(10, db / 20);
}

class VoiceBus {
  private ac?: AudioContext;
  private voiceIn?: GainNode;     // input gain for all voice sources
  private master?: GainNode;      // final stage → destination
  private srcNodes: Array<MediaElementAudioSourceNode | MediaStreamAudioSourceNode> = [];
  private lastBeepAt = 0;         // ms
  private ttsCooldownMs = 250;    // block starting TTS within ± this window

  ensure(){
    if (!this.ac) {
      this.ac = new (window.AudioContext || (window as any).webkitAudioContext)();
      const ac = this.ac;
      this.voiceIn = ac.createGain();
      this.master = ac.createGain();
      this.voiceIn.gain.value = 1.0;
      this.master.gain.value = 1.0;
      this.voiceIn.connect(this.master).connect(ac.destination);
    }
    return this.ac!;
  }

  /** Attach a HTMLAudioElement (e.g., Realtime API audio tag) to the voice bus. */
  attachElement(el: HTMLAudioElement){
    const ac = this.ensure();
    const node = ac.createMediaElementSource(el);
    node.connect(this.voiceIn!);
    this.srcNodes.push(node);
  }

  /** Attach a MediaStream (e.g., RTCPeerConnection remote stream) to the voice bus. */
  attachStream(stream: MediaStream){
    const ac = this.ensure();
    const node = ac.createMediaStreamSource(stream);
    node.connect(this.voiceIn!);
    this.srcNodes.push(node);
  }

  /** Set absolute voice gain in dB (0 = unity). */
  setGainDb(db: number){
    this.ensure();
    const g = dbToGain(db);
    const t = this.ac!.currentTime;
    this.voiceIn!.gain.cancelScheduledValues(t);
    this.voiceIn!.gain.setTargetAtTime(g, t, 0.015);
  }

  /** Smooth duck: -6 dB for `ms`, then return. Idempotent if overlapping. */
  duck(ms = 250, depthDb = -6){
    this.ensure();
    const ac = this.ac!;
    const now = ac.currentTime;
    const cur = this.voiceIn!.gain.value;
    const target = dbToGain(depthDb);
    this.voiceIn!.gain.cancelScheduledValues(now);
    // move to duck level quickly
    this.voiceIn!.gain.setTargetAtTime(target, now, 0.01);
    // release after ms
    const releaseAt = now + Math.max(0.05, ms/1000);
    this.voiceIn!.gain.setTargetAtTime(1.0, releaseAt, 0.04);
    this.lastBeepAt = Date.now();
  }

  /** Guard: defer TTS start if a beep just fired. */
  guardTTSStart<T>(fn: () => T, extraDelayMs = 0): T | void {
    const since = Date.now() - this.lastBeepAt;
    const wait = Math.max(0, this.ttsCooldownMs - since) + extraDelayMs;
    if (wait <= 0) return fn();
    setTimeout(fn, wait);
  }
}

export const voiceBus = new VoiceBus();


⸻

2) /coach/beeps.ts — hook ducking to the bus (small tweak)

If you already added the Beeps engine from the Beep Map one‑pager, just set the ducker to call voiceBus.duck(ms).

// inside your /coach/beeps.ts after constructing the engine
import { voiceBus } from '@/audio/voiceBus';

beeps.setDucker((on, ms) => {
  if (on) voiceBus.duck(ms);
});


⸻

3) Realtime API audio → bus (two common ways)

A) Using an <audio> tag fed by your Realtime stream

// Create the element once (muted until connected)
const rtAudio = new Audio();
rtAudio.autoplay = true; rtAudio.playsInline = true; rtAudio.crossOrigin = 'anonymous';
// Set srcObject from your RTCPeerConnection remote stream
peerConnection.ontrack = (ev) => {
  const [stream] = ev.streams;
  rtAudio.srcObject = stream; // plays immediately
  // Route element → bus for ducking
  voiceBus.attachElement(rtAudio);
};

B) Attaching the MediaStream directly (no <audio>)

peerConnection.ontrack = (ev) => {
  const [stream] = ev.streams;
  voiceBus.attachStream(stream); // routed via WebAudio graph
};

If you were previously playing the <audio> directly and attaching to the bus, do not double‑route. Route once via the bus.

⸻

4) Browser TTS adapter using the guard window

You can’t dynamically duck speechSynthesis mid‑utterance, but you can avoid collisions by deferring starts around beeps and setting a lower base volume.

// /audio/ttsAdapter.ts
import { voiceBus } from '@/audio/voiceBus';

export function speakTTS(text: string){
  const utter = new SpeechSynthesisUtterance(text);
  utter.lang = 'en-US'; utter.rate = 1.0; utter.pitch = 1.0; utter.volume = 0.95; // base volume
  voiceBus.guardTTSStart(() => window.speechSynthesis.speak(utter));
}

Wire it:

// In your TimelineContext build
import { speakTTS } from '@/audio/ttsAdapter';
const ctx = { /* ... */ speak: (t) => speakTTS(t), /* ... */ };


⸻

5) Realtime voice adapter (sends text, plays through bus)

Pseudocode — adapt to your Realtime client. The key is that all audio renders through the bus (element or stream), and you don’t start speech inside the guard window.

// /audio/realtimeVoice.ts
import { voiceBus } from '@/audio/voiceBus';

export async function speakRealtime(text: string){
  // guard start near beeps to avoid talking over pips
  voiceBus.guardTTSStart(() => {
    // send text to your Realtime API / TTS synth
    // e.g., ws.send(JSON.stringify({ type:'response.create', response: { instructions: text } }));
  });
}

// When your WebRTC connection becomes active, route its remote stream to the bus:
export function attachRealtimeStream(stream: MediaStream){
  voiceBus.attachStream(stream);
}

Wire it:

// In your TimelineContext build
import { speakRealtime, attachRealtimeStream } from '@/audio/realtimeVoice';

// When RTCPeerConnection ontrack fires
attachRealtimeStream(remoteStream);

const ctx = { /* ... */ speak: (t) => speakRealtime(t), /* ... */ };


⸻

6) End‑to‑end glue (ctx + beeps)

// In player bootstrap
import { beeps } from '@/coach/beeps';
import { voiceBus } from '@/audio/voiceBus';

// Ensure AudioContext is started by a user gesture
window.addEventListener('pointerdown', () => {
  try { (voiceBus as any).ensure?.(); } catch {}
}, { once: true });

// Already done earlier:
beeps.setDucker((on, ms) => { if (on) voiceBus.duck(ms); });


⸻

7) Quick sanity checks
	•	Start a 3:00 rep‑round scheduler: hear short, short, LONG at start; voice lines never start inside ±250ms of beeps.
	•	While a line is speaking (Realtime voice), fire a beep: voice drops by ~6 dB during the beep and returns smoothly.
	•	TTS path: lines may start slightly delayed if a beep just played (guard window), avoiding pile‑ups.

⸻

8) Notes & gotchas
	•	iOS requires a user gesture to start AudioContext; call voiceBus.ensure() on first tap.
	•	Don’t mix direct element playback and bus playback for the same audio; route once to avoid comb filtering.
	•	If you have music in‑app, consider a musicBus with its own GainNode and duck both voice and music together (deeper integration later).

⸻

Done. Hook beeps → voiceBus.duck(ms), route your voice source through the bus, and swap your ctx.speak to the guarded adapters above. This keeps pips crisp and speech clean, even with flaky networks.